{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4e7a5f",
   "metadata": {},
   "source": [
    "# Azure Document Intelligence Docker ReadAPI & phi3\n",
    "\n",
    "<img src=\"container.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385eadf8",
   "metadata": {},
   "source": [
    "https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/containers/install-run?view=doc-intel-3.0.0&tabs=read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37075f",
   "metadata": {},
   "source": [
    "## 1. Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8dbb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-formrecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83b75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doc_intelligences_container import *\n",
    "start_docker_compose(\"docker-compose.yml\")\n",
    "endpoint=get_endpoint_from_docker_compose(\"docker-compose.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3874cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Afficher le répertoire de travail courant (pour vérification)\n",
    "print(f\"Répertoire de travail courant : {os.getcwd()}\")\n",
    "\n",
    "# Importer directement le script (puisqu'ils sont dans le même répertoire)\n",
    "try:\n",
    "    from doc_intelligences_container import *\n",
    "    print(\"Module doc_intelligences_container importé avec succès.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Erreur d'importation : {e}\")\n",
    "    print(\"Vérifiez que doc_intelligences_container.py est dans le même répertoire que le notebook.\")\n",
    "    print(f\"Contenu de sys.path : {sys.path}\")  # Afficher sys.path pour le débogage\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e01abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... le reste de votre code (utilisant les fonctions de doc_intelligences_container)\n",
    "yml_path = \"docker-compose.yml\"\n",
    "azure_env_path = \"azure.env\"\n",
    "document_file = \"../document/Phi4-TechReport.pdf\"\n",
    "\n",
    "# Utilisation du module importé avec gestion des erreurs\n",
    "try:\n",
    "    result_start_docker = start_docker_compose(yml_path)\n",
    "    print(result_start_docker)\n",
    "\n",
    "    endpoint = get_endpoint_from_docker_compose(yml_path)\n",
    "    key = get_key(azure_env_path)\n",
    "\n",
    "    if endpoint.startswith(\"http://\"):\n",
    "        azure_document_intelligence_client = get_document_intelligence_client(endpoint, key)\n",
    "\n",
    "        start = time.time()\n",
    "        with open(document_file, \"rb\") as file:\n",
    "            poller = azure_document_intelligence_client.begin_analyze_document(\n",
    "                \"prebuilt-read\",\n",
    "                file.read())\n",
    "            result = poller.result()\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"Done in {time.strftime('%H:%M:%S.' + str(elapsed % 1)[2:15], time.gmtime(elapsed))}\")\n",
    "        get_results(result)\n",
    "    else:\n",
    "        print(endpoint)  # Affiche le message d'erreur\n",
    "except AttributeError as e:\n",
    "    print(f\"Erreur d'attribut : {e}. Vérifiez que la fonction existe dans le module importé.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Erreur de fichier non trouvé : {e}. Vérifiez le chemin du fichier.\")\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur inattendue s'est produite : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abc2322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "#import openai\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_docker_compose(yml_path: str):\n",
    "    \"\"\"\n",
    "    Starts containers defined in a docker-compose.yml file.\n",
    "\n",
    "    Args:\n",
    "        yml_path (str): Path to the docker-compose.yml file.\n",
    "\n",
    "    Returns:\n",
    "        str: Success or error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the provided path exists and is a valid file\n",
    "        yml_file = Path(yml_path)\n",
    "        if not yml_file.is_file():\n",
    "            return f\"Error: The specified file '{yml_path}' does not exist or is not a valid file.\"\n",
    "\n",
    "        # Execute the docker-compose up -d command\n",
    "        subprocess.run(\n",
    "            [\"docker-compose\", \"-f\", str(yml_file), \"up\", \"-d\"],\n",
    "            check=True\n",
    "        )\n",
    "        return f\"Containers started successfully using the file '{yml_path}'.\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error while starting containers: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f083e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = start_docker_compose(r\"docker-compose.yml\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.documentintelligence\n",
    "print(\"Azure Document Intelligence version: \", azure.ai.documentintelligence.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caab1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_info():\n",
    "    \"\"\"\n",
    "    Get system information\n",
    "    \"\"\"\n",
    "    system_info = {\n",
    "        \"System\": platform.system(),\n",
    "        \"Machine\": platform.machine(),\n",
    "        \"Processor\": platform.processor(),\n",
    "    }\n",
    "    return system_info\n",
    "\n",
    "\n",
    "info = get_system_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da203b3f",
   "metadata": {},
   "source": [
    "## 2. Settings for Azure Document Intelligence in a connected container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d16248c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_endpoint_from_docker_compose(yml_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the port from a docker-compose.yml file and constructs the endpoint URL.\n",
    "\n",
    "    Args:\n",
    "        yml_path (str): Path to the docker-compose.yml file.\n",
    "\n",
    "    Returns:\n",
    "        str: The constructed endpoint (e.g., \"http://localhost:5000\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the provided path exists and is a valid file\n",
    "        yml_file = Path(yml_path)\n",
    "        if not yml_file.is_file():\n",
    "            return f\"Error: The specified file '{yml_path}' does not exist or is not a valid file.\"\n",
    "\n",
    "        # Load the docker-compose.yml file\n",
    "        with open(yml_file, 'r') as file:\n",
    "            compose_data = yaml.safe_load(file)\n",
    "\n",
    "        # Extract the port mapping from the YAML content\n",
    "        services = compose_data.get('services', {})\n",
    "        for service_name, service_config in services.items():\n",
    "            ports = service_config.get('ports', [])\n",
    "            for port_mapping in ports:\n",
    "                # Split the port mapping (e.g., \"5000:5000\")\n",
    "                if isinstance(port_mapping, str) and ':' in port_mapping:\n",
    "                    host_port, container_port = port_mapping.split(':')\n",
    "                    if container_port == '5000':  # Look for the container port 5000\n",
    "                        return f\"http://localhost:{host_port}\"\n",
    "\n",
    "        return \"Error: No service exposing port 5000 found in the docker-compose.yml file.\"\n",
    "\n",
    "    except yaml.YAMLError as e:\n",
    "        return f\"Error parsing YAML file: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yml_path = r\"docker-compose.yml\"\n",
    "endpoint = get_endpoint_from_docker_compose(yml_path)\n",
    "print(endpoint)\n",
    "\n",
    "\n",
    "#endpoint = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(azure_env_path: str) -> str:\n",
    "    load_dotenv(azure_env_path)\n",
    "    key = os.getenv(\"azure_doc_intelligence_key\")\n",
    "    return key\n",
    "\n",
    "key = get_key(\"azure.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa83a9",
   "metadata": {},
   "source": [
    "http://localhost:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b3ee2",
   "metadata": {},
   "source": [
    "http://localhost:5000/api-docs/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014773a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_intelligence_client(endpoint, key):\n",
    "    azure_document_intelligence_client = DocumentAnalysisClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "    return azure_document_intelligence_client\n",
    "\n",
    "azure_document_intelligence_client = get_document_intelligence_client(endpoint, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63015e7",
   "metadata": {},
   "source": [
    "## 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25bd4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(page, line):\n",
    "    \"\"\"\n",
    "    Extracts words from a given page that fall within the specified line spans.\n",
    "\n",
    "    Args:\n",
    "        page (Page): The page object containing words to be extracted.\n",
    "        line (Line): The line object containing spans that define the boundaries for word extraction.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of words that are within the specified line spans.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for word in page.words:\n",
    "        if _in_span(word, line.spans):\n",
    "            result.append(word)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0907b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_file(file_path):\n",
    "    \"\"\"\n",
    "    Counts the number of words in a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of words in the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        words = text.split()\n",
    "        return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac7b120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _in_span(word, spans):\n",
    "    \"\"\"\n",
    "    Checks if a word falls within any of the specified spans.\n",
    "\n",
    "    Args:\n",
    "        word (Word): The word object to be checked.\n",
    "        spans (list): A list of span objects that define the boundaries for the word.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the word is within any of the spans, False otherwise.\n",
    "    \"\"\"\n",
    "    for span in spans:\n",
    "        if word.span.offset >= span.offset and (\n",
    "                word.span.offset + word.span.length) <= (span.offset +\n",
    "                                                         span.length):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f4bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(result):\n",
    "    \"\"\"\n",
    "    Prints the Azure Document Intelligence results.\n",
    "\n",
    "    This function prints detailed information about the document's layout, such as the presence of handwritten content, \n",
    "    the dimensions of each page, the lines and words within each page, selection marks, barcodes, and tables.\n",
    "\n",
    "    Input: result\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    print(\"Document Layout Analysis:\")\n",
    "    print(\"\\033[1;31;34m\")\n",
    "\n",
    "    if result.styles and any([style.is_handwritten\n",
    "                              for style in result.styles]):\n",
    "        print(\"Document contains handwritten content\\n\")\n",
    "    else:\n",
    "        print(\"Document does not contain handwritten content\\n\")\n",
    "\n",
    "    for page in result.pages:\n",
    "        print(f\"*** Analyzing layout from page #{page.page_number} ***\")\n",
    "        print(\n",
    "            f\"Page has width: {page.width} and height: {page.height}, measured with unit: {page.unit}\"\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        if page.lines:\n",
    "            for line_idx, line in enumerate(page.lines):\n",
    "                words = get_words(page, line)\n",
    "                print(\n",
    "                    f\"\\n- Line # {line_idx} has word count {len(words)} and text '{line.content}' \"\n",
    "                    f\"within bounding polygon '{line.polygon}'\")\n",
    "\n",
    "                for word in words:\n",
    "                    print(\n",
    "                        f\"\\tWord '{word.content}' has a confidence of {word.confidence}\"\n",
    "                    )\n",
    "\n",
    "        if page.selection_marks:\n",
    "            for selection_mark in page.selection_marks:\n",
    "                print(\n",
    "                    f\"Selection mark is '{selection_mark.state}' within bounding polygon \"\n",
    "                    f\"'{selection_mark.polygon}' and has a confidence of {selection_mark.confidence}\"\n",
    "                )\n",
    "\n",
    "        if page.barcodes:\n",
    "            print(f\"Detected {len(page.barcodes)} barcodes:\")\n",
    "            for barcode_idx, barcode in enumerate(page.barcodes):\n",
    "                print(f\"Barcode #{barcode_idx}: {barcode.value}\")\n",
    "                print(f\"\\tKind: {barcode.kind}\")\n",
    "                print(f\"\\tConfidence: {barcode.confidence}\")\n",
    "                print(f\"\\tBounding regions: {barcode.polygon}\")\n",
    "\n",
    "    if result.tables:\n",
    "        for table_idx, table in enumerate(result.tables):\n",
    "            print(f\"Table # {table_idx} has {table.row_count} rows and \"\n",
    "                  f\"{table.column_count} columns\")\n",
    "            if table.bounding_regions:\n",
    "                for region in table.bounding_regions:\n",
    "                    print(\n",
    "                        f\"Table # {table_idx} location on page: {region.page_number} is {region.polygon}\"\n",
    "                    )\n",
    "            for cell in table.cells:\n",
    "                print(\n",
    "                    f\"Cell[{cell.row_index}][{cell.column_index}] has text '{cell.content}'\"\n",
    "                )\n",
    "            if cell.bounding_regions:\n",
    "                for region in cell.bounding_regions:\n",
    "                    print(\n",
    "                        f\"content on page {region.page_number} is within bounding polygon '{region.polygon}'\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a42dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_document_intelligence_costs(pages: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Azure Document Intelligence costs.\n",
    "    The cost for Prebuilt Models (Layout) is $10 per 1,000 pages.\n",
    "\n",
    "    Output in USD.\n",
    "    \"\"\"\n",
    "    cost = 10 * (pages / 1_000)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57664fd1",
   "metadata": {},
   "source": [
    "## 4. Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6fbfa",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "document_file = \"../document/Phi4-TechReport.pdf\"\n",
    "\n",
    "\n",
    "os.path.exists(document_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with open(document_file, \"rb\") as file:\n",
    "    poller = azure_document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-read\",\n",
    "        file.read())\n",
    "    result = poller.result()\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\n",
    "    f\"Done in {time.strftime('%H:%M:%S.' + str(elapsed % 1)[2:15], time.gmtime(elapsed))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99ec4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs(result):\n",
    "    paragraphs = []\n",
    "    for idx, paragraph in enumerate(result.paragraphs):\n",
    "        item = {\n",
    "            \"id\": \"/paragraphs/\" + str(idx),\n",
    "            \"content\": paragraph.content if paragraph.content else \"\",\n",
    "            \"role\": paragraph.role if paragraph.role else \"\",\n",
    "            \"polygon\": paragraph.get(\"boundingRegions\")[0][\"polygon\"],\n",
    "            \"pageNumber\": paragraph.get(\"boundingRegions\")[0][\"pageNumber\"]\n",
    "        }\n",
    "        paragraphs.append(item)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2aa84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(result):\n",
    "    tables = []\n",
    "    for table_idx, table in enumerate(result.tables):\n",
    "        cells = []\n",
    "        for cell in table.cells: \n",
    "            cells.append( {\n",
    "                \"row_index\": cell.row_index,\n",
    "                \"column_index\": cell.column_index,\n",
    "                \"content\": cell.content,\n",
    "            })\n",
    "        tab = {\n",
    "                \"row_count\": table.row_count,\n",
    "                \"column_count\": table.column_count,\n",
    "                \"cells\": cells\n",
    "        }\n",
    "        tables.append(tab)\n",
    "        return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed872af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee79f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c0ff0",
   "metadata": {},
   "source": [
    "### Exporting results to a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c315d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_file = \"../document/ocr.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb5d6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ocr_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for page in result.pages:\n",
    "        for line in page.lines:\n",
    "            file.write(f\"{line.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd01afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count_words_in_file(ocr_file)\n",
    "print(f\"The number of words in the file {ocr_file} is = {word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file results\n",
    "with open(ocr_file, 'r', encoding=\"utf-8\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a869e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1;31;32m\")\n",
    "for page in result.pages:\n",
    "    for line in page.lines:\n",
    "        print(f\"{line.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe06f5",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f63e5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_file = \"documents/letter.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(document_file)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff42f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = \"prebuilt-read\"\n",
    "\n",
    "with open(document_file, \"rb\") as file:\n",
    "    poller = azure_document_intelligence_client.begin_analyze_document(\"prebuilt-read\", file.read())\n",
    "    result = poller.result()\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Done in {time.strftime('%H:%M:%S.' + str(elapsed % 1)[2:15], time.gmtime(elapsed))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59816dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1;31;32m\")\n",
    "for page in result.pages:\n",
    "    for line in page.lines:\n",
    "        print(f\"{line.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74f8f2",
   "metadata": {},
   "source": [
    "## 5. GenAI using Phi-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26552b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c84d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama show phi3:medium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad6ea10",
   "metadata": {},
   "source": [
    "### With ollama client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7230cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_file = \"documents/ocr.txt\"\n",
    "\n",
    "with open(ocr_file, 'r') as file:\n",
    "    ocr_text = file.read()\n",
    "\n",
    "word_count = count_words_in_file(ocr_file)\n",
    "print(f\"The number of words in the file {ocr_file} is: {word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab056f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"nokeyneeded\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f28132fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi3_ollama_model(prompt, temperature=0.7, model=\"phi3\"):\n",
    "    \"\"\"\n",
    "    Generates a response from the Phi-3 model using the Ollama API.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        temperature (float, optional): The sampling temperature to use.\n",
    "        Defaults to 0.7.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama_client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            n=1,\n",
    "            messages=[{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI helpful assistant.\"\n",
    "            }, {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664967e",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab72613",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Can you summarize this text: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_model(prompt, model=\"phi3:medium\")\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4527886",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Generate a description in one line for this text: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_model(prompt, model=\"phi3\")\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Generate a description in one line for this text with some keywords and emojis: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_model(prompt, model=\"phi3\")\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"What are the companies mentionned in this text: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_model(prompt, model=\"phi3\")\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b322a8",
   "metadata": {},
   "source": [
    "### Using ollama lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb58e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea8e3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi3_ollama_lib_model(prompt, model=\"phi3\"):\n",
    "    \"\"\"\n",
    "    Sends a prompt to the 'phi3' model using the Ollama chat API and returns the response content.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt to be sent to the 'phi3' model.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the response message from the 'phi3' model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model,\n",
    "            messages=[{\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            }],\n",
    "        )\n",
    "        return response.message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"'[Error] An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Generate a one line description for this text: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_lib_model(prompt, model=\"phi3:medium\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff873e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Generate some keywords to describe this text: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_lib_model(prompt)\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043399de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Classify this text into one of these categories: [ART], [TRAVEL], [FINANCE], [IT], [SPORTS] {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_lib_model(prompt)\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103fa429",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"What are the urls mentionned in this text: {ocr_text}\"\n",
    "\n",
    "answer = phi3_ollama_lib_model(prompt)\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d53f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
